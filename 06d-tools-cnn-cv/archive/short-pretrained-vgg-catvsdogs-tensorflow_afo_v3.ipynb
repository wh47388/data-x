{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![data-x](http://oi64.tinypic.com/o858n4.jpg)\n",
    "\n",
    "\n",
    "# CATS vs DOGS \n",
    "## TensorFlow (for Python 2 or 3)\n",
    "---\n",
    "\n",
    "### Code for extracting Bottleneck features and train model \n",
    "\n",
    "**Author:** Alexander Fred Ojala\n",
    "\n",
    "**Copright:** Feel free to do whatever you want with this code.\n",
    "\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls\n",
    "\n",
    "'''\n",
    "Files /Folders needed:\n",
    "\n",
    "data/\n",
    "data-x_hw7_tensorflow_py35.ipynb\n",
    "vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
    "'''\n",
    "''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at files, note all cat images and dog images are unique\n",
    "from __future__ import absolute_import, division, print_function\n",
    "import os\n",
    "for path, dirs, files in os.walk('./data'):\n",
    "    print('FOLDER',path)\n",
    "    for f in files[:4]:\n",
    "        print(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Number of cat training images:', len(next(os.walk('./data/train/cats'))[2]))\n",
    "print('Number of dog training images:', len(next(os.walk('./data/train/dogs'))[2]))\n",
    "print('Number of cat validation images:', len(next(os.walk('./data/validation/cats'))[2]))\n",
    "print('Number of dog validation images:', len(next(os.walk('./data/validation/dogs'))[2]))\n",
    "print('Number of uncategorized test images:', len(next(os.walk('./data/test/catvdog'))[2]))\n",
    "\n",
    "# There should be 1000 train cat images, 1000 train dogs, 400 validation cats, 400 validation dogs, 100 uncategorized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define variables\n",
    "TRAIN_DIR = './data/train/'\n",
    "VAL_DIR = './data/validation/'\n",
    "TEST_DIR = './data/test/' #one mixed category\n",
    "\n",
    "img_width, img_height = 150, 150\n",
    "\n",
    "n_train_samples = 2000\n",
    "n_validation_samples = 800\n",
    "n_epoch = 30\n",
    "n_test_samples = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Important set correct backend and image_dim_ordering\n",
    "**Set tensorflow backend and image_dim_ordering tf**\n",
    "\n",
    "set it in the **keras.json** file\n",
    "\n",
    "On mac it is loacted: ``~/.keras/keras.json`` and / or look here https://keras.io/backend/#switching-from-one-backend-to-another\n",
    "\n",
    "#### For Windows: \n",
    "Start up your python-binary and do the following\n",
    "\n",
    "        import os\n",
    "        print(os.path.expanduser('~'))\n",
    "        # >>> C:\\\\Users\\\\Sascha'  # will look different for different OS\n",
    "\n",
    "- This should be the base-directory\n",
    "- Keras will build a folder .keras there where keras.json resides (if it was already created). If it's not there, create it there\n",
    "- Example: C:\\\\Users\\\\Sascha\\\\.keras\\\\keras.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "K.set_image_dim_ordering('tf') # note that we need to have tensorflow dimension ordering still because of the weigths.\n",
    "print('The backend is:',K.backend())\n",
    "import tensorflow as tf\n",
    "print(K.image_dim_ordering()) # should say tf\n",
    "print(tf.__version__) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Import relevant packages\n",
    "import h5py\n",
    "import os, cv2, random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import ticker\n",
    "import seaborn as sns\n",
    "%matplotlib inline \n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Input, Dropout, Flatten, Convolution2D, MaxPooling2D, Dense, Activation, ZeroPadding2D\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.callbacks import ModelCheckpoint, Callback, EarlyStopping\n",
    "from keras.utils import np_utils\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.preprocessing.image import array_to_img, img_to_array, load_img\n",
    "from keras.models import model_from_json\n",
    "from keras.preprocessing import image\n",
    "\n",
    "from IPython.display import Image, display\n",
    "\n",
    "# fix random seed for reproducibility\n",
    "seed = 7\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This can take ~20mins to run\n",
    "\n",
    "def save_bottleneck_features():\n",
    "\n",
    "    from keras import applications\n",
    "    model = applications.vgg16.VGG16(include_top=False, weights='imagenet', \\\n",
    "                                     input_tensor=None, input_shape=(img_width, img_height,3))\n",
    "    \n",
    "    print('TensorFlow model loaded')\n",
    "\n",
    "    datagen = ImageDataGenerator(rescale=1./255)\n",
    "    \n",
    "    def generate_features(DIR,n_samples,name_str):\n",
    "       \n",
    "        '''This is a generator that will read pictures found in\n",
    "        subfolers of 'data/*', and indefinitely generate\n",
    "        batches of image rescaled images used to predict\n",
    "        the bottleneck features of the images once\n",
    "        using model.predict_generator(**args**)'''\n",
    "\n",
    "        print('Generate '+name_str+' image features')\n",
    "\n",
    "        generator = datagen.flow_from_directory(\n",
    "            DIR,\n",
    "            target_size=(img_width, img_height),\n",
    "            batch_size=32,\n",
    "            class_mode=None,\n",
    "            shuffle=False)\n",
    "        \n",
    "        features = model.predict_generator(generator, n_samples)\n",
    "        np.save('features_'+name_str+'.npy', features) # save bottleneck features to file\n",
    "    \n",
    "    generate_features(TEST_DIR, n_test_samples, 'test')\n",
    "    generate_features(TRAIN_DIR, n_train_samples, 'train')\n",
    "    generate_features(VAL_DIR, n_validation_samples, 'validation')\n",
    "    \n",
    "    print('\\nDone! Bottleneck features have been saved')\n",
    "\n",
    "    \n",
    "save_bottleneck_features()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preface:\n",
    "# Obtain class labels and binary classification for validation data\n",
    "datagen = ImageDataGenerator(rescale=1./255)\n",
    "val_gen = datagen.flow_from_directory(VAL_DIR,target_size=(img_width, img_height),\n",
    "                                        batch_size=32,class_mode=None,shuffle=False)\n",
    "\n",
    "val_labels = val_gen.classes\n",
    "\n",
    "print('\\nClassifications:\\n',val_gen.class_indices)\n",
    "print('\\nClass labels:\\n',val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Load in bottleneck features\n",
    "# Run the code below to train your CNN with the training data\n",
    "\n",
    "train_data = np.load('features_train.npy')\n",
    "train_labels = np.array([0] * (n_train_samples // 2) + [1] * (n_train_samples // 2))\n",
    "\n",
    "validation_data = np.load('features_validation.npy')\n",
    "# same as val_labels above\n",
    "validation_labels = np.array([0] * (n_validation_samples // 2) + [1] * (n_validation_samples // 2))\n",
    "\n",
    "# Add top layers trained ontop of extracted VGG features\n",
    "# Small fully connected model trained on top of the stored features\n",
    "model = Sequential()\n",
    "model.add(Flatten(input_shape=train_data.shape[1:]))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "'''\n",
    "#We end the model with a single unit and a sigmoid activation, which is perfect for a binary classification. \n",
    "#To go with it we will also use the binary_crossentropy loss to train our model.\n",
    "\n",
    "'''\n",
    "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.fit(train_data, train_labels,\n",
    "          nb_epoch=n_epoch, batch_size=32,\n",
    "          validation_data=(validation_data, validation_labels)) # fit the model\n",
    "print('Done!')"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
